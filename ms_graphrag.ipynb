{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing the Libraries\n",
    "This section installs all the necessary libraries that are required for running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install graphrag nest_asyncio httpx langchain-ollama "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Initialize Indexing for creating the configuration files. \n",
    "--------------------------------------------------------\n",
    "--init: Creates the necessary configuration files for indexing.\n",
    "--root .: Sets the root directory to the current directory.\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m graphrag.index --init  --root . \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Indexing for creating the configuration files. \n",
    "--------------------------------------------------------\n",
    "rerunning the indexing process on the root directory ( . )\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m graphrag.index --root . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a Query with Graphrag\n",
    "This section runs a query with Graphrag.\n",
    "\n",
    "--root .: Sets the root directory to the current directory.\n",
    "--method local: Indicates that the method to be used is local.\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m graphrag.query --root . --method local  \"Who can be granted temporary protection? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Characters Until a Marker in Query Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "\n",
    "def count_characters_until_marker(output, marker=\"SUCCESS: Local Search Response:\"):\n",
    "    \"\"\"\n",
    "    Counts the number of characters from the start of the output\n",
    "    until the end of the marker string.\n",
    "\n",
    "    Args:\n",
    "        output (str): The entire output text to search.\n",
    "        marker (str): The marker to search for in the output text.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of characters till the end of the marker.\n",
    "             Returns -1 if the marker is not found.\n",
    "    \"\"\"\n",
    "    marker_index = output.find(marker)\n",
    "    if marker_index != -1:\n",
    "        return marker_index + len(marker)\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "result = subprocess.run(['python3', '-m', 'graphrag.query', '--root', '.', '--method', 'local', \"Who can be granted temporary protection?\"], stdout=subprocess.PIPE)\n",
    "output = result.stdout.decode('utf-8')\n",
    "\n",
    "# Count the characters till the end of the marker\n",
    "char_count = count_characters_until_marker(output)\n",
    "print(f\"Number of characters until the end of marker: {char_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Queries with Starting Prompts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_len_cat(text):\n",
    "    return round((len(text) * 1.5) + char_count)\n",
    " \n",
    "def create_query_with_start_prompt(row):\n",
    "    answer_length = ' The answer should be maximum ' + str(get_len_cat(row['answer'])) + ' characters.'\n",
    "    if pd.isnull(row['start_with_prompt']):\n",
    "        query= row['question'] + answer_length\n",
    "    else:\n",
    "        query= str(row['start_with_prompt']) + row['question'] + answer_length    \n",
    "    return query\n",
    "\n",
    "def create_query_without_start_prompt(row):\n",
    "    answer_length = ' The answer should be maximum ' + str(get_len_cat(row['answer'])) + ' characters.'\n",
    "    query=  row['question'] + answer_length    \n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(r\"hyperrag\\MSgraphrag\\testdata\\migri_faq.csv\", sep=\";\")\n",
    "# print some rows where there is a valid start_with_prompt\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying Graphrag for Each Row and Adding the Result to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_marker = \"SUCCESS: Local Search Response:\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    query = create_query_without_start_prompt(row)\n",
    "    print(f\"Query: {query}\")\n",
    "    result = subprocess.run(['python3', '-m', 'graphrag.query', '--root', '.', '--method', 'local', query], stdout=subprocess.PIPE)\n",
    "    output = result.stdout.decode('utf-8')\n",
    "    if start_marker in output:\n",
    "        extracted_text = output.split(start_marker)[-1].strip()\n",
    "    else:\n",
    "        print(\"Error: 'SUCCESS: Local Search Response:' not found in output\")\n",
    "        extracted_text = None\n",
    "    # add the extracted text to the dataframe as a new column \"ms_graphgraph_answer\"\n",
    "    df.loc[index, \"ms_graphgraph_answer\"] = extracted_text\n",
    "    print(df.loc[index, \"ms_graphgraph_answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the df with the new column into csv\n",
    "\n",
    "df.to_csv(r\"hyperrag\\MSgraphrag\\testdata\\migi_faq_with_ms_graphgraph.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take each row in the dataframe, create query and fet the answer from the graphrag,, then store it as a new column in dataframe\n",
    "\n",
    "# query is run like this  !python3 -m graphrag.query --root . --method local  \"Who can be granted temporary protection? \n",
    "\n",
    "import subprocess\n",
    "import json\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def query_graphrag(query):\n",
    "    result = subprocess.run(['python3', '-m', 'graphrag.query', '--root', '.', '--method', 'local', query], stdout=subprocess.PIPE)\n",
    "    # get the answer from the result\n",
    "    answer = json.loads(result.stdout)['answer']\n",
    "    return answer\n",
    "\n",
    "\n",
    "# df['query'] = df.apply(create_query_without_start_prompt, axis=1)\n",
    "# df['answer'] = df['query'].apply(lambda x: query_graphrag(x))\n",
    "df['ms_graphrag_answer'] = df['question'].apply(lambda x: query_graphrag(x))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
